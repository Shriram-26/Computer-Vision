{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shriram-26/Computer-Vision/blob/main/shree_med.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m7GR-ImJzHB",
        "outputId": "9ad57ff2-e440-434e-86a9-f1454c279c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/803.2 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 2.88G/2.88G [00:17<00:00, 175MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded successfully!\n",
            "Ngrok URL: https://18ddf377c6e7.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 07:45:58] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 07:45:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing audio...\n",
            "Transcribing audio...\n",
            "Audio duration: 247.512 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 07:48:31] \"POST /process HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 07:49:38] \"GET / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing audio...\n",
            "Transcribing audio...\n",
            "Audio duration: 300.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 07:51:12] \"POST /process HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "!pip install flask pyngrok pydub ffmpeg-python openai-whisper google-generativeai --quiet\n",
        "\n",
        "import os, tempfile, re, traceback\n",
        "import json\n",
        "from datetime import timedelta\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# ---------------- API KEYS ----------------\n",
        "GEN_API_KEY = \"AIzaSyCRSWxAMNGLEi5n4KHwtgb06nbDwSwBqt4\"\n",
        "\n",
        "client = genai.Client(api_key=GEN_API_KEY)\n",
        "\n",
        "# ---------------- Load Whisper ----------------\n",
        "print(\"Loading Whisper model...\")\n",
        "model = whisper.load_model(\"large\")\n",
        "print(\"Whisper model loaded successfully!\")\n",
        "\n",
        "# ---------------- Supported Languages ----------------\n",
        "LANGUAGES = {\n",
        "    \"en\": \"English\", \"hi\": \"Hindi\", \"mr\": \"Marathi\",\n",
        "    \"ta\": \"Tamil\", \"te\": \"Telugu\", \"gu\": \"Gujarati\",\n",
        "    \"kn\": \"Kannada\", \"bn\": \"Bengali\", \"ur\": \"Urdu\"\n",
        "}\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config[\"UPLOAD_FOLDER\"] = \"/content/uploads\"\n",
        "os.makedirs(app.config[\"UPLOAD_FOLDER\"], exist_ok=True)\n",
        "\n",
        "# ----------- Helper Functions -----------\n",
        "def preprocess_audio(file_path):\n",
        "    try:\n",
        "        print(\"Preprocessing audio...\")\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "        processed_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
        "        audio.export(processed_path, format=\"wav\")\n",
        "        return processed_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocess_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def transcribe_audio(audio_path, chunk_length_sec=60, language=None):\n",
        "    try:\n",
        "        print(\"Transcribing audio...\")\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration = len(audio) / 1000\n",
        "        print(f\"Audio duration: {duration} seconds\")\n",
        "\n",
        "        chunks = [audio[i:i+chunk_length_sec*1000] for i in range(0, len(audio), chunk_length_sec*1000)]\n",
        "        full_text = \"\"\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
        "                chunk.export(temp_audio.name, format=\"wav\")\n",
        "                result = model.transcribe(temp_audio.name, language=language)\n",
        "                start_time = str(timedelta(seconds=i * chunk_length_sec))\n",
        "                full_text += f\"[{start_time}]\\n{result['text'].strip()}\\n\\n\"\n",
        "                os.remove(temp_audio.name)\n",
        "\n",
        "        return full_text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in transcribe_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def correct_text_with_gemini(text, audio_path=None):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      clean_text: human-readable corrected transcription\n",
        "      json_obj:   structured JSON dict representing the same content (flexible schema)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = (\n",
        "    \"You are given an audio transcription along with the original audio file.\\n\"\n",
        "    \"Your tasks:\\n\"\n",
        "    \"1) Correct grammar and spelling.\\n\"\n",
        "    \"2) Improve formatting and readability.\\n\"\n",
        "    \"3) DO NOT change the order of information.\\n\"\n",
        "    \"4) The JSON MUST follow the EXACT SAME SEQUENCE of sections as the corrected transcription.\\n\"\n",
        "    \"5) Every heading and sub-heading in the transcription must appear in the JSON in the same order.\\n\"\n",
        "    \"6) Only include fields that actually exist in the transcription. Do NOT add new fields.\\n\"\n",
        "    \"7) Preserve meaning exactly. No invented data.\\n\\n\"\n",
        "\n",
        "    \"OUTPUT FORMAT (VERY IMPORTANT):\\n\"\n",
        "    \"First output:\\n\"\n",
        "    \"<<<TEXT>>>\\n\"\n",
        "    \"[clean corrected transcription formatted normally (NO asterisks, NO markdown)]\\n\"\n",
        "    \"<<<JSON>>>\\n\"\n",
        "    \"[valid JSON only, no comments]\\n\\n\"\n",
        "\n",
        "    f\"Transcription:\\n{text}\"\n",
        ")\n",
        "\n",
        "        parts = [types.Part.from_text(text=prompt)]\n",
        "\n",
        "        if audio_path:\n",
        "            with open(audio_path, \"rb\") as f:\n",
        "                audio_bytes = f.read()\n",
        "            parts.append(types.Part.from_bytes(data=audio_bytes, mime_type=\"audio/wav\"))\n",
        "\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=parts,\n",
        "        )\n",
        "\n",
        "        resp_text = (resp.text or \"\").strip()\n",
        "        clean_text = text  # fallback\n",
        "        json_obj = None\n",
        "\n",
        "        if \"<<<JSON>>>\" in resp_text:\n",
        "            text_part, json_part = resp_text.split(\"<<<JSON>>>\", 1)\n",
        "\n",
        "            if \"<<<TEXT>>>\" in text_part:\n",
        "                text_part = text_part.split(\"<<<TEXT>>>\", 1)[1]\n",
        "\n",
        "                clean_text = text_part.strip()\n",
        "                clean_text = re.sub(r\"\\*+\", \"\", clean_text)\n",
        "                json_str = json_part.strip()\n",
        "\n",
        "            try:\n",
        "                json_obj = json.loads(json_str)\n",
        "            except Exception as e:\n",
        "                print(\"JSON parse error from Gemini:\", e)\n",
        "                # keep raw JSON for debugging\n",
        "                json_obj = {\"rawJson\": json_str}\n",
        "        else:\n",
        "            # if model ignored markers, just clean markdown and no JSON\n",
        "            clean_text = re.sub(r\"\\*+\", \"\", resp_text).strip()\n",
        "            json_obj = None\n",
        "\n",
        "        return clean_text, json_obj\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in correct_text_with_gemini: {e}\")\n",
        "        # fallback: original text, no JSON\n",
        "        return text, None\n",
        "\n",
        "# ----------- HTML Template -----------\n",
        "INDEX_HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>Speech-to-Text</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Upload Audio</h1>\n",
        "  <form method=\"POST\" action=\"/process\" enctype=\"multipart/form-data\">\n",
        "    <label>Audio File:</label>\n",
        "    <input type=\"file\" name=\"file\" accept=\"audio/*\" required><br><br>\n",
        "    <label>Source Language (e.g., en, hi):</label>\n",
        "    <input type=\"text\" name=\"language\" value=\"en\"><br><br>\n",
        "    <button type=\"submit\">Transcribe</button>\n",
        "  </form>\n",
        "\n",
        "  {% if results %}\n",
        "  <h2>Results</h2>\n",
        "\n",
        "  <h3>Corrected Transcription:</h3>\n",
        "  <pre>{{ results.corrected_text }}</pre>\n",
        "\n",
        "  {% if results.structured_json %}\n",
        "  <h3>Structured JSON:</h3>\n",
        "  <pre>{{ results.structured_json | tojson(indent=2) }}</pre>\n",
        "  {% endif %}\n",
        "  {% endif %}\n",
        "\n",
        "  {% if error %}\n",
        "  <h3 style=\"color:red;\">Error: {{ error }}</h3>\n",
        "  {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ----------- Routes -----------\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template_string(INDEX_HTML, results=None, error=None)\n",
        "\n",
        "@app.route(\"/process\", methods=[\"POST\"])\n",
        "def process_audio():\n",
        "    try:\n",
        "        if \"file\" not in request.files:\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No audio file uploaded\")\n",
        "\n",
        "        file = request.files[\"file\"]\n",
        "        lang = request.form.get(\"language\", \"en\")\n",
        "\n",
        "        if file.filename == \"\":\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No file selected\")\n",
        "\n",
        "        save_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
        "        file.save(save_path)\n",
        "\n",
        "        processed_path = preprocess_audio(save_path)\n",
        "        transcribed_text = transcribe_audio(processed_path, language=lang)\n",
        "        corrected_text, structured_json = correct_text_with_gemini(transcribed_text, processed_path)\n",
        "\n",
        "\n",
        "        if os.path.exists(processed_path):\n",
        "            os.remove(processed_path)\n",
        "        if os.path.exists(save_path):\n",
        "            os.remove(save_path)\n",
        "\n",
        "        results = {\n",
        "            \"raw_transcription\": transcribed_text,\n",
        "            \"corrected_text\": corrected_text,\n",
        "            \"structured_json\": structured_json,\n",
        "        }\n",
        "\n",
        "        return render_template_string(INDEX_HTML, results=results, error=None)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing audio: {str(e)}\"\n",
        "        traceback.print_exc()\n",
        "        return render_template_string(INDEX_HTML, results=None, error=error_msg)\n",
        "\n",
        "# ---------------- ngrok setup ----------------\n",
        "conf.get_default().auth_token = \"35VPeqrSlq4sokUPQpyykibij0z_6wNDXdmZbWAQJqPcx4xLq\"\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"Ngrok URL:\", public_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\",port=port)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok pydub ffmpeg-python openai-whisper google-generativeai --quiet\n",
        "\n",
        "import os, tempfile, re, traceback\n",
        "import json\n",
        "from datetime import timedelta\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# ---------------- API KEYS ----------------\n",
        "GEN_API_KEY = \"AIzaSyCRSWxAMNGLEi5n4KHwtgb06nbDwSwBqt4\"\n",
        "\n",
        "client = genai.Client(api_key=GEN_API_KEY)\n",
        "\n",
        "# ---------------- Load Whisper ----------------\n",
        "print(\"Loading Whisper model...\")\n",
        "model = whisper.load_model(\"large\")\n",
        "print(\"Whisper model loaded successfully!\")\n",
        "\n",
        "# ---------------- Supported Languages ----------------\n",
        "LANGUAGES = {\n",
        "    \"en\": \"English\", \"hi\": \"Hindi\", \"mr\": \"Marathi\",\n",
        "    \"ta\": \"Tamil\", \"te\": \"Telugu\", \"gu\": \"Gujarati\",\n",
        "    \"kn\": \"Kannada\", \"bn\": \"Bengali\", \"ur\": \"Urdu\"\n",
        "}\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config[\"UPLOAD_FOLDER\"] = \"/content/uploads\"\n",
        "os.makedirs(app.config[\"UPLOAD_FOLDER\"], exist_ok=True)\n",
        "\n",
        "# ----------- Helper Functions -----------\n",
        "def preprocess_audio(file_path):\n",
        "    try:\n",
        "        print(\"Preprocessing audio...\")\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "        processed_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
        "        audio.export(processed_path, format=\"wav\")\n",
        "        return processed_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocess_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def transcribe_audio(audio_path, chunk_length_sec=60, language=None):\n",
        "    try:\n",
        "        print(\"Transcribing audio...\")\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration = len(audio) / 1000\n",
        "        print(f\"Audio duration: {duration} seconds\")\n",
        "\n",
        "        chunks = [audio[i:i+chunk_length_sec*1000] for i in range(0, len(audio), chunk_length_sec*1000)]\n",
        "        full_text = \"\"\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
        "                chunk.export(temp_audio.name, format=\"wav\")\n",
        "                result = model.transcribe(temp_audio.name, language=language)\n",
        "                start_time = str(timedelta(seconds=i * chunk_length_sec))\n",
        "                full_text += f\"[{start_time}]\\n{result['text'].strip()}\\n\\n\"\n",
        "                os.remove(temp_audio.name)\n",
        "\n",
        "        return full_text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in transcribe_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def correct_text_with_gemini(text, audio_path=None):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      clean_text: human-readable corrected transcription\n",
        "      json_obj:   structured JSON dict representing the same content (flexible schema)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = (\n",
        "    \"You are given an audio transcription along with the original audio file.\\n\"\n",
        "    \"Your tasks:\\n\"\n",
        "    \"1) Correct grammar and spelling.\\n\"\n",
        "    \"2) Improve formatting and readability.\\n\"\n",
        "    \"3) DO NOT change the order of information.\\n\"\n",
        "    \"4) The JSON MUST follow the EXACT SAME SEQUENCE of sections as the corrected transcription.\\n\"\n",
        "    \"5) Every heading and sub-heading in the transcription must appear in the JSON in the same order.\\n\"\n",
        "    \"6) Only include fields that actually exist in the transcription. Do NOT add new fields.\\n\"\n",
        "    \"7) Preserve meaning exactly. No invented data.\\n\\n\"\n",
        "\n",
        "    \"OUTPUT FORMAT (VERY IMPORTANT):\\n\"\n",
        "    \"First output:\\n\"\n",
        "    \"<<<TEXT>>>\\n\"\n",
        "    \"[clean corrected transcription formatted normally (NO asterisks, NO markdown)]\\n\"\n",
        "    \"<<<JSON>>>\\n\"\n",
        "    \"[valid JSON only, no comments]\\n\\n\"\n",
        "\n",
        "    f\"Transcription:\\n{text}\"\n",
        ")\n",
        "\n",
        "        parts = [types.Part.from_text(text=prompt)]\n",
        "\n",
        "        if audio_path:\n",
        "            with open(audio_path, \"rb\") as f:\n",
        "                audio_bytes = f.read()\n",
        "            parts.append(types.Part.from_bytes(data=audio_bytes, mime_type=\"audio/wav\"))\n",
        "\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=parts,\n",
        "        )\n",
        "\n",
        "        resp_text = (resp.text or \"\").strip()\n",
        "        clean_text = text  # fallback\n",
        "        json_obj = None\n",
        "\n",
        "        if \"<<<JSON>>>\" in resp_text:\n",
        "            text_part, json_part = resp_text.split(\"<<<JSON>>>\", 1)\n",
        "\n",
        "            if \"<<<TEXT>>>\" in text_part:\n",
        "                text_part = text_part.split(\"<<<TEXT>>>\", 1)[1]\n",
        "\n",
        "                clean_text = text_part.strip()\n",
        "                clean_text = re.sub(r\"\\*+\", \"\", clean_text)\n",
        "                json_str = json_part.strip()\n",
        "\n",
        "            try:\n",
        "                json_obj = json.loads(json_str)\n",
        "            except Exception as e:\n",
        "                print(\"JSON parse error from Gemini:\", e)\n",
        "                # keep raw JSON for debugging\n",
        "                json_obj = {\"rawJson\": json_str}\n",
        "        else:\n",
        "            # if model ignored markers, just clean markdown and no JSON\n",
        "            clean_text = re.sub(r\"\\*+\", \"\", resp_text).strip()\n",
        "            json_obj = None\n",
        "\n",
        "        return clean_text, json_obj\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in correct_text_with_gemini: {e}\")\n",
        "        # fallback: original text, no JSON\n",
        "        return text, None\n",
        "\n",
        "# ----------- HTML Template -----------\n",
        "INDEX_HTML = \"\"\"\n",
        "<!doctype html>4\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>Speech-to-Text</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Upload Audio</h1>\n",
        "  <form method=\"POST\" action=\"/process\" enctype=\"multipart/form-data\">\n",
        "    <label>Audio File:</label>\n",
        "    <input type=\"file\" name=\"file\" accept=\"audio/*\" required><br><br>\n",
        "    <label>Source Language (e.g., en, hi):</label>\n",
        "    <input type=\"text\" name=\"language\" value=\"en\"><br><br>\n",
        "    <button type=\"submit\">Transcribe</button>\n",
        "  </form>\n",
        "\n",
        "  {% if results %}\n",
        "  <h2>Results</h2>\n",
        "\n",
        "  <h3>Corrected Transcription:</h3>\n",
        "  <pre>{{ results.corrected_text }}</pre>\n",
        "\n",
        "  {% if results.structured_json %}\n",
        "  <h3>Structured JSON:</h3>\n",
        "  <pre>{{ results.structured_json | tojson(indent=2) }}</pre>\n",
        "  {% endif %}\n",
        "  {% endif %}\n",
        "\n",
        "  {% if error %}\n",
        "  <h3 style=\"color:red;\">Error: {{ error }}</h3>\n",
        "  {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ----------- Routes -----------\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template_string(INDEX_HTML, results=None, error=None)\n",
        "\n",
        "@app.route(\"/process\", methods=[\"POST\"])\n",
        "def process_audio():\n",
        "    try:\n",
        "        if \"file\" not in request.files:\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No audio file uploaded\")\n",
        "\n",
        "        file = request.files[\"file\"]\n",
        "        lang = request.form.get(\"language\", \"en\")\n",
        "\n",
        "        if file.filename == \"\":\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No file selected\")\n",
        "\n",
        "        save_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
        "        file.save(save_path)\n",
        "\n",
        "        processed_path = preprocess_audio(save_path)\n",
        "        transcribed_text = transcribe_audio(processed_path, language=lang)\n",
        "        corrected_text, structured_json = correct_text_with_gemini(transcribed_text, processed_path)\n",
        "\n",
        "\n",
        "        if os.path.exists(processed_path):\n",
        "            os.remove(processed_path)\n",
        "        if os.path.exists(save_path):\n",
        "            os.remove(save_path)\n",
        "\n",
        "        results = {\n",
        "            \"raw_transcription\": transcribed_text,\n",
        "            \"corrected_text\": corrected_text,\n",
        "            \"structured_json\": structured_json,\n",
        "        }\n",
        "\n",
        "        return render_template_string(INDEX_HTML, results=results, error=None)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing audio: {str(e)}\"\n",
        "        traceback.print_exc()\n",
        "        return render_template_string(INDEX_HTML, results=None, error=error_msg)\n",
        "\n",
        "# ---------------- ngrok setup ----------------\n",
        "conf.get_default().auth_token = \"32ECeIuD0tL9WRaRUbldZXOwIa8_uo4NzZG79isxV8Ct6txf\"\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"Ngrok URL:\", public_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\",port=port)"
      ],
      "metadata": {
        "id": "NWIjgLRXZBUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-TQoAc7ZY5vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flask pyngrok pydub ffmpeg-python openai-whisper google-generativeai --quiet\n",
        "\n",
        "import os, tempfile, re, traceback\n",
        "import json\n",
        "from datetime import timedelta\n",
        "from flask import Flask, request, jsonify, render_template_string\n",
        "from pydub import AudioSegment\n",
        "import whisper\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "# ---------------- API KEYS ----------------\n",
        "GEN_API_KEY = \"AIzaSyCRSWxAMNGLEi5n4KHwtgb06nbDwSwBqt4\"\n",
        "\n",
        "client = genai.Client(api_key=GEN_API_KEY)\n",
        "\n",
        "# ---------------- Load Whisper ----------------\n",
        "print(\"Loading Whisper model...\")\n",
        "model = whisper.load_model(\"large\")\n",
        "print(\"Whisper model loaded successfully!\")\n",
        "\n",
        "# ---------------- Supported Languages ----------------\n",
        "LANGUAGES = {\n",
        "    \"en\": \"English\", \"hi\": \"Hindi\", \"mr\": \"Marathi\",\n",
        "    \"ta\": \"Tamil\", \"te\": \"Telugu\", \"gu\": \"Gujarati\",\n",
        "    \"kn\": \"Kannada\", \"bn\": \"Bengali\", \"ur\": \"Urdu\"\n",
        "}\n",
        "\n",
        "app = Flask(__name__)\n",
        "app.config[\"UPLOAD_FOLDER\"] = \"/content/uploads\"\n",
        "os.makedirs(app.config[\"UPLOAD_FOLDER\"], exist_ok=True)\n",
        "\n",
        "# ----------- Helper Functions -----------\n",
        "def preprocess_audio(file_path):\n",
        "    try:\n",
        "        print(\"Preprocessing audio...\")\n",
        "        audio = AudioSegment.from_file(file_path)\n",
        "        audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "        processed_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n",
        "        audio.export(processed_path, format=\"wav\")\n",
        "        return processed_path\n",
        "    except Exception as e:\n",
        "        print(f\"Error in preprocess_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def transcribe_audio(audio_path, chunk_length_sec=60, language=None):\n",
        "    try:\n",
        "        print(\"Transcribing audio...\")\n",
        "        audio = AudioSegment.from_file(audio_path)\n",
        "        duration = len(audio) / 1000\n",
        "        print(f\"Audio duration: {duration} seconds\")\n",
        "\n",
        "        chunks = [audio[i:i+chunk_length_sec*1000] for i in range(0, len(audio), chunk_length_sec*1000)]\n",
        "        full_text = \"\"\n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_audio:\n",
        "                chunk.export(temp_audio.name, format=\"wav\")\n",
        "                result = model.transcribe(temp_audio.name, language=language)\n",
        "                start_time = str(timedelta(seconds=i * chunk_length_sec))\n",
        "                full_text += f\"[{start_time}]\\n{result['text'].strip()}\\n\\n\"\n",
        "                os.remove(temp_audio.name)\n",
        "\n",
        "        return full_text.strip()\n",
        "    except Exception as e:\n",
        "        print(f\"Error in transcribe_audio: {e}\")\n",
        "        raise\n",
        "\n",
        "def correct_text_with_gemini(text, audio_path=None):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      clean_text: human-readable corrected transcription\n",
        "      json_obj:   structured JSON dict representing the same content (flexible schema)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        prompt = (\n",
        "    \"You are given an audio transcription along with the original audio file.\\n\"\n",
        "    \"Your tasks:\\n\"\n",
        "    \"1) Correct grammar and spelling.\\n\"\n",
        "    \"2) Improve formatting and readability.\\n\"\n",
        "    \"3) DO NOT change the order of information.\\n\"\n",
        "    \"4) The JSON MUST follow the EXACT SAME SEQUENCE of sections as the corrected transcription.\\n\"\n",
        "    \"5) Every heading and sub-heading in the transcription must appear in the JSON in the same order.\\n\"\n",
        "    \"6) Only include fields that actually exist in the transcription. Do NOT add new fields.\\n\"\n",
        "    \"7) Preserve meaning exactly. No invented data.\\n\"\n",
        "    \"8)IMPORTANT: Do NOT use Markdown formatting or code fences in the JSON output.\\n\\n\"\n",
        "\n",
        "\n",
        "    \"OUTPUT FORMAT (VERY IMPORTANT):\\n\"\n",
        "    \"First output:\\n\"\n",
        "    \"<<<TEXT>>>\\n\"\n",
        "    \"[clean corrected transcription formatted normally (NO asterisks, NO markdown)]\\n\"\n",
        "    \"<<<JSON>>>\\n\"\n",
        "    \"[PURE JSON ONLY, NO ``` MARKDOWN FENCES, NO EXTRA TEXT]\\n\\n\"\n",
        "\n",
        "    f\"Transcription:\\n{text}\"\n",
        ")\n",
        "\n",
        "        parts = [types.Part.from_text(text=prompt)]\n",
        "\n",
        "        if audio_path:\n",
        "            with open(audio_path, \"rb\") as f:\n",
        "                audio_bytes = f.read()\n",
        "            parts.append(types.Part.from_bytes(data=audio_bytes, mime_type=\"audio/wav\"))\n",
        "\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=parts,\n",
        "        )\n",
        "\n",
        "        resp_text = (resp.text or \"\").strip()\n",
        "        clean_text = text  # fallback\n",
        "        json_obj = None\n",
        "\n",
        "        if \"<<<JSON>>>\" in resp_text:\n",
        "            text_part, json_part = resp_text.split(\"<<<JSON>>>\", 1)\n",
        "\n",
        "            if \"<<<TEXT>>>\" in text_part:\n",
        "                text_part = text_part.split(\"<<<TEXT>>>\", 1)[1]\n",
        "\n",
        "            clean_text = re.sub(r\"\\*+\", \"\", text_part).strip()\n",
        "            json_str = json_part.strip()\n",
        "\n",
        "            # Clean Markdown JSON block\n",
        "            json_clean = re.sub(r\"^```json|```$\", \"\", json_str.strip(), flags=re.IGNORECASE).strip()\n",
        "\n",
        "            try:\n",
        "                json_obj = json.loads(json_clean)\n",
        "            except Exception as e:\n",
        "                print(\"JSON parse error:\", e)\n",
        "                json_obj = {\"rawJson\": json_str}\n",
        "        else:\n",
        "            # if model ignored markers, just clean markdown and no JSON\n",
        "            clean_text = re.sub(r\"\\*+\", \"\", resp_text).strip()\n",
        "            json_obj = None\n",
        "\n",
        "        return clean_text, json_obj\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in correct_text_with_gemini: {e}\")\n",
        "        # fallback: original text, no JSON\n",
        "        return text, None\n",
        "\n",
        "# ----------- HTML Template -----------\n",
        "INDEX_HTML = \"\"\"\n",
        "<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "  <meta charset=\"utf-8\">\n",
        "  <title>Speech-to-Text</title>\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Upload Audio</h1>\n",
        "  <form method=\"POST\" action=\"/process\" enctype=\"multipart/form-data\">\n",
        "    <label>Audio File:</label>\n",
        "    <input type=\"file\" name=\"file\" accept=\"audio/*\" required><br><br>\n",
        "    <label>Source Language (e.g., en, hi):</label>\n",
        "    <input type=\"text\" name=\"language\" value=\"en\"><br><br>\n",
        "    <button type=\"submit\">Transcribe</button>\n",
        "  </form>\n",
        "\n",
        "  {% if results %}\n",
        "  <h2>Results</h2>\n",
        "\n",
        "  <h3>Corrected Transcription:</h3>\n",
        "  <pre>{{ results.corrected_text }}</pre>\n",
        "\n",
        "  {% if results.structured_json %}\n",
        "  <h3>Structured JSON:</h3>\n",
        "  <pre>{{ results.structured_json | tojson(indent=2) }}</pre>\n",
        "  {% endif %}\n",
        "  {% endif %}\n",
        "\n",
        "  {% if error %}\n",
        "  <h3 style=\"color:red;\">Error: {{ error }}</h3>\n",
        "  {% endif %}\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# ----------- Routes -----------\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template_string(INDEX_HTML, results=None, error=None)\n",
        "\n",
        "@app.route(\"/process\", methods=[\"POST\"])\n",
        "def process_audio():\n",
        "    try:\n",
        "        if \"file\" not in request.files:\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No audio file uploaded\")\n",
        "\n",
        "        file = request.files[\"file\"]\n",
        "        lang = request.form.get(\"language\", \"en\")\n",
        "\n",
        "        if file.filename == \"\":\n",
        "            return render_template_string(INDEX_HTML, results=None, error=\"No file selected\")\n",
        "\n",
        "        save_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], file.filename)\n",
        "        file.save(save_path)\n",
        "\n",
        "        processed_path = preprocess_audio(save_path)\n",
        "        transcribed_text = transcribe_audio(processed_path, language=lang)\n",
        "        corrected_text, structured_json = correct_text_with_gemini(transcribed_text, processed_path)\n",
        "\n",
        "\n",
        "        if os.path.exists(processed_path):\n",
        "            os.remove(processed_path)\n",
        "        if os.path.exists(save_path):\n",
        "            os.remove(save_path)\n",
        "\n",
        "        results = {\n",
        "            \"raw_transcription\": transcribed_text,\n",
        "            \"corrected_text\": corrected_text,\n",
        "            \"structured_json\": structured_json,\n",
        "        }\n",
        "\n",
        "        return render_template_string(INDEX_HTML, results=results, error=None)\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error processing audio: {str(e)}\"\n",
        "        traceback.print_exc()\n",
        "        return render_template_string(INDEX_HTML, results=None, error=error_msg)\n",
        "\n",
        "# ---------------- ngrok setup ----------------\n",
        "conf.get_default().auth_token = \"35VJWwscw95v1LZHmGZ2VoMa9D1_NELmUH3FKLTFCoJChtiT\"\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\"Ngrok URL:\", public_url)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(host=\"0.0.0.0\",port=port)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mvOaA7cRIYf",
        "outputId": "ba889cf5-bea0-4437-c1cd-5fd75b058514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Whisper model...\n",
            "Whisper model loaded successfully!\n",
            "Ngrok URL: https://caf641733577.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 06:56:04] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 06:56:04] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing audio...\n",
            "Transcribing audio...\n",
            "Audio duration: 300.33 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [15/Nov/2025 06:57:57] \"POST /process HTTP/1.1\" 200 -\n"
          ]
        }
      ]
    }
  ]
}